{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53ad108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías y cargar base de datos\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"incident_event_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "164c79e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Valores_faltantes  Porcentaje_faltantes\n",
      "number                                   0                  0.00\n",
      "incident_state                           0                  0.00\n",
      "active                                   0                  0.00\n",
      "reassignment_count                       0                  0.00\n",
      "reopen_count                             0                  0.00\n",
      "sys_mod_count                            0                  0.00\n",
      "made_sla                                 0                  0.00\n",
      "caller_id                               29                  0.02\n",
      "opened_by                             4835                  3.41\n",
      "opened_at                                0                  0.00\n",
      "sys_created_by                       53076                 37.45\n",
      "sys_created_at                       53076                 37.45\n",
      "sys_updated_by                           0                  0.00\n",
      "sys_updated_at                           0                  0.00\n",
      "contact_type                             0                  0.00\n",
      "location                                76                  0.05\n",
      "category                                78                  0.06\n",
      "subcategory                            111                  0.08\n",
      "u_symptom                            32964                 23.26\n",
      "cmdb_ci                             141267                 99.69\n",
      "impact                                   0                  0.00\n",
      "urgency                                  0                  0.00\n",
      "priority                                 0                  0.00\n",
      "assignment_group                     14213                 10.03\n",
      "assigned_to                          27496                 19.40\n",
      "knowledge                                0                  0.00\n",
      "u_priority_confirmation                  0                  0.00\n",
      "notify                                   0                  0.00\n",
      "problem_id                          139417                 98.38\n",
      "rfc                                 140721                 99.30\n",
      "vendor                              141468                 99.83\n",
      "caused_by                           141689                 99.98\n",
      "closed_code                            714                  0.50\n",
      "resolved_by                            226                  0.16\n",
      "resolved_at                           3141                  2.22\n",
      "closed_at                                0                  0.00\n",
      "Total de filas duplicadas: 0\n",
      "\n",
      "No se encontraron filas duplicadas.\n"
     ]
    }
   ],
   "source": [
    "#Reemplazar \"?\" por NaN\n",
    "df=df.replace(\"?\",np.nan)\n",
    "\n",
    "# Total de filas\n",
    "total_filas = len(df)\n",
    "\n",
    "# Conteo de vacíos\n",
    "faltantes = df.isna().sum()\n",
    "\n",
    "# Porcentaje de vacíos\n",
    "porcentaje_faltantes = (faltantes / total_filas) * 100\n",
    "\n",
    "# DataFrame resumen\n",
    "faltantes_df = pd.DataFrame({\n",
    "    \"Valores_faltantes\": faltantes,\n",
    "    \"Porcentaje_faltantes\": porcentaje_faltantes.round(2)\n",
    "})\n",
    "\n",
    "print(faltantes_df)\n",
    "\n",
    "# --- Análisis de duplicados ---\n",
    "\n",
    "# Número total de filas duplicadas\n",
    "total_duplicados = df.duplicated().sum()\n",
    "print(f\"Total de filas duplicadas: {total_duplicados}\")\n",
    "\n",
    "# Mostrar las filas duplicadas (si existen)\n",
    "if total_duplicados > 0:\n",
    "    print(\"\\n=== Filas duplicadas ===\")\n",
    "    display(df[df.duplicated(keep=False)])  # keep=False muestra todas las ocurrencias\n",
    "else:\n",
    "    print(\"\\nNo se encontraron filas duplicadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3d4cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Porcentaje de valores faltantes por columna ===\n",
      "caused_by                  99.98\n",
      "vendor                     99.83\n",
      "cmdb_ci                    99.69\n",
      "rfc                        99.30\n",
      "problem_id                 98.38\n",
      "sys_created_by             37.45\n",
      "sys_created_at             37.45\n",
      "u_symptom                  23.26\n",
      "assigned_to                19.40\n",
      "assignment_group           10.03\n",
      "opened_by                   3.41\n",
      "resolved_at                 2.22\n",
      "closed_code                 0.50\n",
      "resolved_by                 0.16\n",
      "subcategory                 0.08\n",
      "category                    0.06\n",
      "location                    0.05\n",
      "caller_id                   0.02\n",
      "incident_state              0.00\n",
      "number                      0.00\n",
      "reassignment_count          0.00\n",
      "active                      0.00\n",
      "contact_type                0.00\n",
      "sys_updated_by              0.00\n",
      "made_sla                    0.00\n",
      "sys_mod_count               0.00\n",
      "reopen_count                0.00\n",
      "opened_at                   0.00\n",
      "sys_updated_at              0.00\n",
      "u_priority_confirmation     0.00\n",
      "notify                      0.00\n",
      "priority                    0.00\n",
      "impact                      0.00\n",
      "urgency                     0.00\n",
      "knowledge                   0.00\n",
      "closed_at                   0.00\n",
      "dtype: float64\n",
      "\n",
      "Columnas a eliminar (>5% nulos): ['sys_created_by', 'sys_created_at', 'u_symptom', 'cmdb_ci', 'assignment_group', 'assigned_to', 'problem_id', 'rfc', 'vendor', 'caused_by']\n",
      "\n",
      "Shape original: (141712, 36)\n",
      "Shape después de limpieza: (141712, 26)\n"
     ]
    }
   ],
   "source": [
    "# --- Calcular porcentaje de nulos por columna ---\n",
    "porc_nulos = (df.isna().sum() / len(df)) * 100\n",
    "\n",
    "print(\"=== Porcentaje de valores faltantes por columna ===\")\n",
    "print(porc_nulos.sort_values(ascending=False).round(2))\n",
    "\n",
    "# --- Seleccionar columnas a eliminar (más del 5% de nulos) ---\n",
    "cols_drop = porc_nulos[porc_nulos > 5].index.tolist()\n",
    "\n",
    "print(f\"\\nColumnas a eliminar (>5% nulos): {cols_drop}\")\n",
    "\n",
    "# --- Eliminar columnas ---\n",
    "df_limpio = df.drop(columns=cols_drop)\n",
    "\n",
    "print(f\"\\nShape original: {df.shape}\")\n",
    "print(f\"Shape después de limpieza: {df_limpio.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b549e01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Estadísticas descriptivas de resolution_time ===\n",
      "count    138571.00\n",
      "mean         11.23\n",
      "std          27.12\n",
      "min           0.00\n",
      "25%           0.17\n",
      "50%           3.06\n",
      "75%          10.92\n",
      "max         336.26\n",
      "Name: resolution_time, dtype: float64\n",
      "\n",
      "=== Estadísticas descriptivas de closure_time ===\n",
      "count    56316.00\n",
      "mean        73.38\n",
      "std        105.24\n",
      "min       -289.96\n",
      "25%        -22.65\n",
      "50%         67.05\n",
      "75%        162.27\n",
      "max        555.63\n",
      "Name: closure_time, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santy\\AppData\\Local\\Temp\\ipykernel_41548\\4098534172.py:2: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_limpio[\"opened_at\"] = pd.to_datetime(df_limpio[\"opened_at\"], errors=\"coerce\")\n",
      "C:\\Users\\santy\\AppData\\Local\\Temp\\ipykernel_41548\\4098534172.py:3: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df_limpio[\"resolved_at\"] = pd.to_datetime(df_limpio[\"resolved_at\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "# --- Convertir a datetime ---\n",
    "df_limpio[\"opened_at\"] = pd.to_datetime(df_limpio[\"opened_at\"], errors=\"coerce\")\n",
    "df_limpio[\"resolved_at\"] = pd.to_datetime(df_limpio[\"resolved_at\"], errors=\"coerce\")\n",
    "df_limpio[\"closed_at\"] = pd.to_datetime(df_limpio[\"closed_at\"], errors=\"coerce\")\n",
    "\n",
    "# --- Crear métricas derivadas en días ---\n",
    "df_limpio[\"resolution_time\"] = (df_limpio[\"resolved_at\"] - df_limpio[\"opened_at\"]).dt.total_seconds() / 86400\n",
    "df_limpio[\"closure_time\"] = (df_limpio[\"closed_at\"] - df_limpio[\"opened_at\"]).dt.total_seconds() / 86400\n",
    "\n",
    "# --- Estadísticas descriptivas ---\n",
    "print(\"\\n=== Estadísticas descriptivas de resolution_time ===\")\n",
    "print(df_limpio[\"resolution_time\"].describe().round(2))\n",
    "\n",
    "print(\"\\n=== Estadísticas descriptivas de closure_time ===\")\n",
    "print(df_limpio[\"closure_time\"].describe().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73bef65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impact: ['Medium' 'High' 'Low']\n",
      "urgency: ['Medium' 'Low' 'High']\n",
      "priority: ['Moderate' 'High' 'Low' 'Critical']\n"
     ]
    }
   ],
   "source": [
    "# Normalizar impact, urgency y priority a solo texto limpio\n",
    "for col in [\"impact\", \"urgency\", \"priority\"]:\n",
    "    if col in df_limpio.columns:\n",
    "        # Convertir a string, quitar números + guiones, recortar espacios\n",
    "        df_limpio[col] = (\n",
    "            df_limpio[col]\n",
    "            .astype(str)\n",
    "            .str.replace(r\"^\\d+\\s*-\\s*\", \"\", regex=True)  # quita \"1 -\", \"2 -\" etc.\n",
    "            .str.strip()  # quita espacios extras\n",
    "        )\n",
    "\n",
    "# Ver valores únicos después de limpiar\n",
    "for col in [\"impact\", \"urgency\", \"priority\"]:\n",
    "    if col in df_limpio.columns:\n",
    "        print(f\"{col}: {df_limpio[col].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9438864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Resumen de outliers y limpieza ===\n",
      "Registros eliminados en reassignment_count (>15): 87\n",
      "Outliers en reassignment_count (IQR): 19548 (13.80%)\n",
      "Outliers en reopen_count (IQR): 2256 (1.59%)\n"
     ]
    }
   ],
   "source": [
    "# --- Asegurar tipo numérico ---\n",
    "df_limpio[\"reassignment_count\"] = pd.to_numeric(df_limpio[\"reassignment_count\"], errors=\"coerce\")\n",
    "df_limpio[\"reopen_count\"] = pd.to_numeric(df_limpio[\"reopen_count\"], errors=\"coerce\")\n",
    "\n",
    "# --- 1) Eliminar registros con reassignment_count > 15 ---\n",
    "n_eliminados = (df_limpio[\"reassignment_count\"] > 15).sum()\n",
    "df_limpio = df_limpio[df_limpio[\"reassignment_count\"] <= 15]\n",
    "\n",
    "# --- 2) Outliers en reassignment_count (criterio IQR) ---\n",
    "q1_r = df_limpio[\"reassignment_count\"].quantile(0.25)\n",
    "q3_r = df_limpio[\"reassignment_count\"].quantile(0.75)\n",
    "iqr_r = q3_r - q1_r\n",
    "limite_sup_r = q3_r + 1.5 * iqr_r\n",
    "\n",
    "df_limpio[\"is_outlier_reassignment\"] = df_limpio[\"reassignment_count\"] > limite_sup_r\n",
    "\n",
    "# --- 3) Outliers en reopen_count (criterio IQR, sin eliminar registros) ---\n",
    "q1_o = df_limpio[\"reopen_count\"].quantile(0.25)\n",
    "q3_o = df_limpio[\"reopen_count\"].quantile(0.75)\n",
    "iqr_o = q3_o - q1_o\n",
    "limite_sup_o = q3_o + 1.5 * iqr_o\n",
    "\n",
    "df_limpio[\"is_outlier_reopen\"] = df_limpio[\"reopen_count\"] > limite_sup_o\n",
    "\n",
    "# --- 4) Asegurar tipo booleano ---\n",
    "df_limpio[\"is_outlier_reassignment\"] = df_limpio[\"is_outlier_reassignment\"].astype(bool)\n",
    "df_limpio[\"is_outlier_reopen\"] = df_limpio[\"is_outlier_reopen\"].astype(bool)\n",
    "\n",
    "# --- 5) Resumen ---\n",
    "total_post = len(df_limpio)\n",
    "outliers_reassignment = df_limpio[\"is_outlier_reassignment\"].sum()\n",
    "outliers_reopen = df_limpio[\"is_outlier_reopen\"].sum()\n",
    "\n",
    "print(\"=== Resumen de outliers y limpieza ===\")\n",
    "print(f\"Registros eliminados en reassignment_count (>15): {n_eliminados}\")\n",
    "print(f\"Outliers en reassignment_count (IQR): {outliers_reassignment} ({outliers_reassignment/total_post*100:.2f}%)\")\n",
    "print(f\"Outliers en reopen_count (IQR): {outliers_reopen} ({outliers_reopen/total_post*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bff6b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Resumen limpieza temporal y calidad ===\n",
      "Registros eliminados por filtro temporal (opened_at > 2017-01-01): 829\n",
      "Registros eliminados por inconsistencias (resolved_at/closed_at < opened_at): 17602\n",
      "Registros marcados como inválidos (resolution_time < 0 o closure_time < 0): 0\n",
      "Registros marcados como outliers (resolution_time > 365 días): 0\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Filtro temporal: opened_at <= 2017-02-28 ---\n",
    "cutoff = pd.Timestamp(\"2017-01-01\")\n",
    "n0 = len(df_limpio)\n",
    "df_limpio = df_limpio[df_limpio[\"opened_at\"] <= cutoff].copy()\n",
    "elim_temporal = n0 - len(df_limpio)\n",
    "\n",
    "# --- 2) Eliminar incoherencias: resolved_at < opened_at o closed_at < opened_at ---\n",
    "incoh_mask = (\n",
    "    (df_limpio[\"resolved_at\"].notna() & df_limpio[\"opened_at\"].notna() & (df_limpio[\"resolved_at\"] < df_limpio[\"opened_at\"])) |\n",
    "    (df_limpio[\"closed_at\"].notna()   & df_limpio[\"opened_at\"].notna() & (df_limpio[\"closed_at\"]   < df_limpio[\"opened_at\"]))\n",
    ")\n",
    "elim_incoh = int(incoh_mask.sum())\n",
    "df_limpio = df_limpio[~incoh_mask].copy()\n",
    "\n",
    "# --- 3) Métricas derivadas (días) ---\n",
    "df_limpio[\"resolution_time\"] = (df_limpio[\"resolved_at\"] - df_limpio[\"opened_at\"]).dt.total_seconds() / 86400\n",
    "df_limpio[\"closure_time\"]    = (df_limpio[\"closed_at\"]   - df_limpio[\"opened_at\"]).dt.total_seconds() / 86400\n",
    "\n",
    "# --- 4) Flags de calidad ---\n",
    "# Inválidos: tiempos negativos (no se eliminan, solo se marcan)\n",
    "df_limpio[\"is_invalid_time\"] = (\n",
    "    (df_limpio[\"resolution_time\"] < 0) | (df_limpio[\"closure_time\"] < 0)\n",
    ").fillna(False).astype(bool)\n",
    "\n",
    "# Outliers: resolution_time > 365 días (no se eliminan, solo se marcan)\n",
    "df_limpio[\"is_outlier_resolution_time\"] = (df_limpio[\"resolution_time\"] > 365).fillna(False).astype(bool)\n",
    "\n",
    "# --- 5) Resumen solicitado ---\n",
    "n_invalid  = int(df_limpio[\"is_invalid_time\"].sum())\n",
    "n_outliers = int(df_limpio[\"is_outlier_resolution_time\"].sum())\n",
    "\n",
    "print(\"=== Resumen limpieza temporal y calidad ===\")\n",
    "print(f\"Registros eliminados por filtro temporal (opened_at > 2017-01-01): {elim_temporal}\")\n",
    "print(f\"Registros eliminados por inconsistencias (resolved_at/closed_at < opened_at): {elim_incoh}\")\n",
    "print(f\"Registros marcados como inválidos (resolution_time < 0 o closure_time < 0): {n_invalid}\")\n",
    "print(f\"Registros marcados como outliers (resolution_time > 365 días): {n_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c29b5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos después de agrupar:\n",
      "contact_type\n",
      "Phone    122618\n",
      "Otros       576\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Agrupar contact_type ---\n",
    "df_limpio[\"contact_type\"] = np.where(\n",
    "    df_limpio[\"contact_type\"] == \"Phone\", \"Phone\", \"Otros\"\n",
    ")\n",
    "\n",
    "# --- Verificar resultado ---\n",
    "print(\"Valores únicos después de agrupar:\")\n",
    "print(df_limpio[\"contact_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab545851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas actuales en df_limpio:\n",
      "['number', 'incident_state', 'active', 'reassignment_count', 'reopen_count', 'sys_mod_count', 'made_sla', 'caller_id', 'opened_by', 'opened_at', 'sys_updated_by', 'sys_updated_at', 'contact_type', 'location', 'category', 'subcategory', 'impact', 'urgency', 'knowledge', 'u_priority_confirmation', 'notify', 'closed_code', 'resolved_by', 'resolved_at', 'closed_at', 'resolution_time', 'closure_time', 'is_outlier_reassignment', 'is_outlier_reopen', 'is_invalid_time', 'is_outlier_resolution_time']\n"
     ]
    }
   ],
   "source": [
    "###### Priority no es independiente.\n",
    "\n",
    "# En la tabla que mostraste, cada combinación de impact + urgency siempre da una única priority.\n",
    "#Ejemplo: Impact = High + Urgency = High → Priority = Critical (100% de los casos).\n",
    "#Eso significa que priority es una función determinística de impact y urgency, no un dato nuevo.\n",
    "\n",
    "# --- Eliminar la columna priority ---\n",
    "df_limpio = df_limpio.drop(columns=[\"priority\"])\n",
    "\n",
    "# --- Verificar ---\n",
    "print(\"Columnas actuales en df_limpio:\")\n",
    "print(df_limpio.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d602830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Limpieza de tiempos ===\n",
      "Filas eliminadas por resolution_time > 130 días: 4249\n",
      "Outliers closure_time > 130 días (marcados, no eliminados): 18851\n",
      "\n",
      "Tipos de las columnas de flags:\n",
      "is_outlier_resolution_time    bool\n",
      "is_outlier_closure_time       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- Asegurar que las columnas sean numéricas ---\n",
    "df_limpio[\"resolution_time\"] = pd.to_numeric(df_limpio[\"resolution_time\"], errors=\"coerce\")\n",
    "df_limpio[\"closure_time\"]    = pd.to_numeric(df_limpio[\"closure_time\"], errors=\"coerce\")\n",
    "\n",
    "# --- 1) Crear columnas booleanas de outliers ---\n",
    "df_limpio[\"is_outlier_resolution_time\"] = df_limpio[\"resolution_time\"] > 130\n",
    "df_limpio[\"is_outlier_closure_time\"]    = df_limpio[\"closure_time\"] > 130\n",
    "\n",
    "# --- 2) Eliminar registros con resolution_time > 130 ---\n",
    "n_prev = len(df_limpio)\n",
    "df_limpio = df_limpio[df_limpio[\"resolution_time\"] <= 130].copy()\n",
    "n_drop = n_prev - len(df_limpio)\n",
    "\n",
    "# --- 3) Resumen ---\n",
    "print(\"=== Limpieza de tiempos ===\")\n",
    "print(f\"Filas eliminadas por resolution_time > 130 días: {n_drop}\")\n",
    "print(f\"Outliers closure_time > 130 días (marcados, no eliminados): {df_limpio['is_outlier_closure_time'].sum()}\")\n",
    "\n",
    "# --- 4) Verificación de tipos ---\n",
    "print(\"\\nTipos de las columnas de flags:\")\n",
    "print(df_limpio[[\"is_outlier_resolution_time\", \"is_outlier_closure_time\"]].dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
